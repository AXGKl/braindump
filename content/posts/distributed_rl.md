+++
title = "Distributed Reinforcement Learning"
author = ["Jethro Kuan"]
lastmod = 2019-12-27T12:03:28+08:00
draft = false
math = true
+++

## History of Distributed RL {#history-of-distributed-rl}

1.  DQN <a id="e3433750724eb4eebeebd0d71a7608d6" href="#mnih2013playing" title="Mnih, Kavukcuoglu, Silver, Graves, Antonoglou, Wierstra \&amp; Riedmiller, Playing atari with deep reinforcement learning, {arXiv preprint arXiv:1312.5602}, v(), (2013).">(Mnih et al., 2013)</a>: [§mnih2013\_atari\_deeprl]({{< relref "mnih2013_atari_deeprl" >}})
2.  GORILA <a id="b957e624e257f357391145bdcb6b933a" href="#nair15_massiv_paral_method_deep_reinf_learn" title="Nair, Srinivasan, Blackwell, Sam, Alcicek, Fearon, Maria, Alessandro De, Panneershelvam, , Suleyman, Beattie, Petersen, Stig, Legg, Mnih, , Kavukcuoglu \&amp; Silver, Massively Parallel Methods for Deep Reinforcement  Learning, {CoRR}, v(), (2015).">(Nair et al., 2015)</a>
3.  A3C <a id="5ee60195703614202558f73eaeb64891" href="#mnih16_async_method_deep_reinf_learn" title="Mnih, Badia, Puigdom\`enech, Mirza, Graves, , Lillicrap, Harley, , Silver \&amp; Kavukcuoglu, Asynchronous Methods for Deep Reinforcement  Learning, {CoRR}, v(), (2016).">(Mnih et al., 2016)</a>
4.  IMPALA <a id="fed7cc1da7873c242b1275e7b01b5b49" href="#espeholt18_impal" title="Espeholt, Soyer, Munos, , Simonyan, Mnih, Ward, Tom, Doron, Firoiu, Harley, Tim, Dunning, Legg, \&amp; Kavukcuoglu, Impala: Scalable Distributed Deep-Rl With Importance  Weighted Actor-Learner Architectures, {CoRR}, v(), (2018).">(Espeholt et al., 2018)</a>
5.  Ape-X <a id="29f359a92adf70279b336852f3d65fd7" href="#horgan18_distr_prior_exper_replay" title="Horgan, Quan, Budden, , Barth-Maron, Hessel, Hasselt, Hado van \&amp; Silver, Distributed Prioritized Experience Replay, {CoRR}, v(), (2018).">(Horgan et al., 2018)</a>
6.  R2D3 <a id="cdf12ddb2a1b0783ca667a5da9dd871f" href="#paine19_makin_effic_use_demon_to" title="Paine, Gulcehre, Shahriari, Bobak, Denil, Hoffman, Soyer, Hubert, Tanburn, Kapturowski, , Rabinowitz, Williams, , Barth-Maron, Wang, Freitas, Nando de \&amp; Team, Making Efficient Use of Demonstrations To Solve Hard  Exploration Problems, {CoRR}, v(), (2019).">(Paine et al., 2019)</a>


## Resources {#resources}

-   [CS285 Fa19 10/30/19 - YouTube](https://www.youtube.com/watch?v=oUnsDUtNsOQ&list=PLkFD6%5F40KJIwhWJpGazJ9VSj9CFMkb79A&index=17&t=0s)

# Bibliography
<a id="mnih2013playing"></a>Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., & Riedmiller, M., *Playing atari with deep reinforcement learning*, arXiv preprint arXiv:1312.5602, *()*,  (2013).  [↩](#e3433750724eb4eebeebd0d71a7608d6)

<a id="nair15_massiv_paral_method_deep_reinf_learn"></a>Nair, A., Srinivasan, P., Blackwell, S., Alcicek, C., Fearon, R., Maria, A. D., Panneershelvam, V., …, *Massively parallel methods for deep reinforcement learning*, CoRR, *()*,  (2015).  [↩](#b957e624e257f357391145bdcb6b933a)

<a id="mnih16_async_method_deep_reinf_learn"></a>Mnih, V., Badia, Adri\`a Puigdom\`enech, Mirza, M., Graves, A., Lillicrap, T. P., Harley, T., Silver, D., …, *Asynchronous methods for deep reinforcement learning*, CoRR, *()*,  (2016).  [↩](#5ee60195703614202558f73eaeb64891)

<a id="espeholt18_impal"></a>Espeholt, L., Soyer, H., Munos, R., Simonyan, K., Mnih, V., Ward, T., Doron, Y., …, *Impala: scalable distributed deep-rl with importance weighted actor-learner architectures*, CoRR, *()*,  (2018).  [↩](#fed7cc1da7873c242b1275e7b01b5b49)

<a id="horgan18_distr_prior_exper_replay"></a>Horgan, D., Quan, J., Budden, D., Barth-Maron, G., Hessel, M., Hasselt, H. v., & Silver, D., *Distributed Prioritized Experience Replay*, CoRR, *()*,  (2018).  [↩](#29f359a92adf70279b336852f3d65fd7)

<a id="paine19_makin_effic_use_demon_to"></a>Paine, T. L., Gulcehre, C., Shahriari, B., Denil, M., Hoffman, M., Soyer, H., Tanburn, R., …, *Making efficient use of demonstrations to solve hard exploration problems*, CoRR, *()*,  (2019).  [↩](#cdf12ddb2a1b0783ca667a5da9dd871f)
