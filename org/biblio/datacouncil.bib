@article{guo17_deepf,
  author =       {Guo, Huifeng and Tang, Ruiming and Ye, Yunming and
                  Li, Zhenguo and He, Xiuqiang},
  title =        {Deepfm: a Factorization-Machine Based Neural Network
                  for Ctr Prediction},
  journal =      {CoRR},
  year =         2017,
  url =          {http://arxiv.org/abs/1703.04247v1},
  abstract =     {Learning sophisticated feature interactions behind
                  user behaviors is critical in maximizing CTR for
                  recommender systems. Despite great progress,
                  existing methods seem to have a strong bias towards
                  low- or high-order interactions, or require
                  expertise feature engineering. In this paper, we
                  show that it is possible to derive an end-to-end
                  learning model that emphasizes both low- and
                  high-order feature interactions. The proposed model,
                  DeepFM, combines the power of factorization machines
                  for recommendation and deep learning for feature
                  learning in a new neural network architecture.
                  Compared to the latest Wide \& Deep model from
                  Google, DeepFM has a shared input to its "wide" and
                  "deep" parts, with no need of feature engineering
                  besides raw features. Comprehensive experiments are
                  conducted to demonstrate the effectiveness and
                  efficiency of DeepFM over the existing models for
                  CTR prediction, on both benchmark data and
                  commercial data.},
  archivePrefix ={arXiv},
  eprint =       {1703.04247},
  primaryClass = {cs.IR},
}
@article{lian18_xdeep,
  author =       {Lian, Jianxun and Zhou, Xiaohuan and Zhang, Fuzheng
                  and Chen, Zhongxia and Xie, Xing and Sun,
                  Guangzhong},
  title =        {Xdeepfm: Combining Explicit and Implicit Feature
                  Interactions for Recommender Systems},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1803.05170v3},
  abstract =     {Combinatorial features are essential for the success
                  of many commercial models. Manually crafting these
                  features usually comes with high cost due to the
                  variety, volume and velocity of raw data in
                  web-scale systems. Factorization based models, which
                  measure interactions in terms of vector product, can
                  learn patterns of combinatorial features
                  automatically and generalize to unseen features as
                  well. With the great success of deep neural networks
                  (DNNs) in various fields, recently researchers have
                  proposed several DNN-based factorization model to
                  learn both low- and high-order feature interactions.
                  Despite the powerful ability of learning an
                  arbitrary function from data, plain DNNs generate
                  feature interactions implicitly and at the bit-wise
                  level. In this paper, we propose a novel Compressed
                  Interaction Network (CIN), which aims to generate
                  feature interactions in an explicit fashion and at
                  the vector-wise level. We show that the CIN share
                  some functionalities with convolutional neural
                  networks (CNNs) and recurrent neural networks
                  (RNNs). We further combine a CIN and a classical DNN
                  into one unified model, and named this new model
                  eXtreme Deep Factorization Machine (xDeepFM). On one
                  hand, the xDeepFM is able to learn certain
                  bounded-degree feature interactions explicitly; on
                  the other hand, it can learn arbitrary low- and
                  high-order feature interactions implicitly. We
                  conduct comprehensive experiments on three
                  real-world datasets. Our results demonstrate that
                  xDeepFM outperforms state-of-the-art models. We have
                  released the source code of xDeepFM at
                  \url{https://github.com/Leavingseason/xDeepFM}.},
  archivePrefix ={arXiv},
  eprint =       {1803.05170},
  primaryClass = {cs.LG},
}
@article{wang18_dkn,
  author =       {Wang, Hongwei and Zhang, Fuzheng and Xie, Xing and
                  Guo, Minyi},
  title =        {Dkn: Deep Knowledge-Aware Network for News
                  Recommendation},
  journal =      {CoRR},
  year =         2018,
  url =          {http://arxiv.org/abs/1801.08284v2},
  abstract =     {Online news recommender systems aim to address the
                  information explosion of news and make personalized
                  recommendation for users. In general, news language
                  is highly condensed, full of knowledge entities and
                  common sense. However, existing methods are unaware
                  of such external knowledge and cannot fully discover
                  latent knowledge-level connections among news. The
                  recommended results for a user are consequently
                  limited to simple patterns and cannot be extended
                  reasonably. Moreover, news recommendation also faces
                  the challenges of high time-sensitivity of news and
                  dynamic diversity of users' interests. To solve the
                  above problems, in this paper, we propose a deep
                  knowledge-aware network (DKN) that incorporates
                  knowledge graph representation into news
                  recommendation. DKN is a content-based deep
                  recommendation framework for click-through rate
                  prediction. The key component of DKN is a
                  multi-channel and word-entity-aligned
                  knowledge-aware convolutional neural network (KCNN)
                  that fuses semantic-level and knowledge-level
                  representations of news. KCNN treats words and
                  entities as multiple channels, and explicitly keeps
                  their alignment relationship during convolution. In
                  addition, to address users' diverse interests, we
                  also design an attention module in DKN to
                  dynamically aggregate a user's history with respect
                  to current candidate news. Through extensive
                  experiments on a real online news platform, we
                  demonstrate that DKN achieves substantial gains over
                  state-of-the-art deep recommendation models. We also
                  validate the efficacy of the usage of knowledge in
                  DKN.},
  archivePrefix ={arXiv},
  eprint =       {1801.08284},
  primaryClass = {stat.ML},
}
